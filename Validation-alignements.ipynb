{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68c5225c-a829-4868-af60-ca7c95326929",
   "metadata": {},
   "source": [
    "## Chargement des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e577869",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80325, 23)\n",
      "(10138, 23)\n",
      "(70187, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>réservoir source</th>\n",
       "      <th>id source</th>\n",
       "      <th>forme principale source</th>\n",
       "      <th>arbitre</th>\n",
       "      <th>date d'arbitrage</th>\n",
       "      <th>niveau de confiance</th>\n",
       "      <th>commentaire</th>\n",
       "      <th>décision d'alignement</th>\n",
       "      <th>nombre de candidats</th>\n",
       "      <th>score algo max</th>\n",
       "      <th>...</th>\n",
       "      <th>id cible</th>\n",
       "      <th>forme principale cible</th>\n",
       "      <th>type de cible 2</th>\n",
       "      <th>réservoir cible 2</th>\n",
       "      <th>id cible 2</th>\n",
       "      <th>forme principale cible 2</th>\n",
       "      <th>type de cible 3</th>\n",
       "      <th>réservoir cible 3</th>\n",
       "      <th>id cible 3</th>\n",
       "      <th>forme principale cible 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>rnv-nz-auth-atc</td>\n",
       "      <td>981023280158302851</td>\n",
       "      <td>Bibliothèque municipale (Angers)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>029461634</td>\n",
       "      <td>Bibliothèque municipale Angers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>rnv-nz-auth-atc</td>\n",
       "      <td>981023280248402851</td>\n",
       "      <td>Verein Ernst Mach (Wien)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9239130434782609</td>\n",
       "      <td>...</td>\n",
       "      <td>029679389</td>\n",
       "      <td>Wiener Kreis 1922-1938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>rnv-nz-auth-atc</td>\n",
       "      <td>981023280266802851</td>\n",
       "      <td>Musée national des monuments français (Paris)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>027559203</td>\n",
       "      <td>Musée national des monuments français Paris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>rnv-nz-auth-atc</td>\n",
       "      <td>981023280267302851</td>\n",
       "      <td>Università di Roma. Istituto di studi bizantin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9818840579710144</td>\n",
       "      <td>...</td>\n",
       "      <td>250577860</td>\n",
       "      <td>Università di Roma Istituto di studi bizantini...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>rnv-nz-auth-atc</td>\n",
       "      <td>981023280267902851</td>\n",
       "      <td>Musée de l'Institut du monde arabe (Paris)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>029373158</td>\n",
       "      <td>Institut du monde arabe Musée</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    réservoir source           id source  \\\n",
       "37   rnv-nz-auth-atc  981023280158302851   \n",
       "129  rnv-nz-auth-atc  981023280248402851   \n",
       "147  rnv-nz-auth-atc  981023280266802851   \n",
       "149  rnv-nz-auth-atc  981023280267302851   \n",
       "151  rnv-nz-auth-atc  981023280267902851   \n",
       "\n",
       "                               forme principale source arbitre  \\\n",
       "37                  Bibliothèque municipale (Angers)       NaN   \n",
       "129                         Verein Ernst Mach (Wien)       NaN   \n",
       "147    Musée national des monuments français (Paris)       NaN   \n",
       "149  Università di Roma. Istituto di studi bizantin...     NaN   \n",
       "151       Musée de l'Institut du monde arabe (Paris)       NaN   \n",
       "\n",
       "    date d'arbitrage niveau de confiance commentaire décision d'alignement  \\\n",
       "37               NaN                 NaN         NaN                  auto   \n",
       "129              NaN                 NaN         NaN                  auto   \n",
       "147              NaN                 NaN         NaN                  auto   \n",
       "149              NaN                 NaN         NaN                  auto   \n",
       "151              NaN                 NaN         NaN                  auto   \n",
       "\n",
       "    nombre de candidats      score algo max  ...   id cible  \\\n",
       "37                    1                 1.0  ...  029461634   \n",
       "129                   1  0.9239130434782609  ...  029679389   \n",
       "147                   1                 1.0  ...  027559203   \n",
       "149                   1  0.9818840579710144  ...  250577860   \n",
       "151                   1                 1.0  ...  029373158   \n",
       "\n",
       "                                forme principale cible type de cible 2  \\\n",
       "37                      Bibliothèque municipale Angers             NaN   \n",
       "129                             Wiener Kreis 1922-1938             NaN   \n",
       "147        Musée national des monuments français Paris             NaN   \n",
       "149  Università di Roma Istituto di studi bizantini...             NaN   \n",
       "151                      Institut du monde arabe Musée             NaN   \n",
       "\n",
       "    réservoir cible 2 id cible 2 forme principale cible 2 type de cible 3  \\\n",
       "37                NaN        NaN                      NaN             NaN   \n",
       "129               NaN        NaN                      NaN             NaN   \n",
       "147               NaN        NaN                      NaN             NaN   \n",
       "149               NaN        NaN                      NaN             NaN   \n",
       "151               NaN        NaN                      NaN             NaN   \n",
       "\n",
       "    réservoir cible 3 id cible 3 forme principale cible 3  \n",
       "37                NaN        NaN                      NaN  \n",
       "129               NaN        NaN                      NaN  \n",
       "147               NaN        NaN                      NaN  \n",
       "149               NaN        NaN                      NaN  \n",
       "151               NaN        NaN                      NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import os\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "from pymarc import parse_xml_to_array\n",
    "import jellyfish\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # Remove copy in place warning for dataframe operations\n",
    "\n",
    "\n",
    "# Définition du fichier d'alignement à vérifier\n",
    "input_file_path = \"input/verif-auto-102024/rapport_20240926010347_alignement-défini_TEST ATC-collectivites_test-collectivites.tsv\"\n",
    "\n",
    "# Définition du fichier de sortie pour les cas suspects\n",
    "output_file_root = \"output/verif-auto-102024/verif-auto-collectivités-ATC\"\n",
    "\n",
    "# Faut-il exporter tous les alignements vérifiés avec une colonne identifiant les cas suspects (True),\n",
    "# ou exporter ces derniers à part (False)?\n",
    "output_in_place = True\n",
    "\n",
    "# Types d'alignement à vérifier\n",
    "valid_types = {'auto'}\n",
    "\n",
    "# Types de validation à effectuer\n",
    "validations = {'idref-local', 'similarité', 'lieux', 'numéros', 'années'}\n",
    "# Les valeurs suivantes sont possibles:\n",
    "# - 'personnes' -> les notices à comparer sont de type personnes\n",
    "# - 'dates' -> compare les dates de vie (personnes uniquement) présentes dans les formes principales source et cible. PEUT être combiné avec 'idref-local'\n",
    "# - 'auteur-titre' ATTENTION cette validation fait un appel d'API IdRef. Utiliser uniquement lorsque nécessaire.\n",
    "# - 'idref-local' -> compare les sous-champs des notices source et cible. Nécessite l'accès à un export des notices IdRef et ATC/RNV\n",
    "# - 'professions' -> compare les sous-champs $c si présents (personnes uniquement). DOIT être combiné avec 'idref-local'\n",
    "# - 'similarité' -> tente de calculer un coéfficient de similarité entre les formes principales. PEUT être combiné avec 'idref-local'\n",
    "# - 'lieux' -> tente de comparer les sous-champs $g si présents (congrès uniquement)\n",
    "# - 'numéros' -> tente de comparer les sous-champs $n si présents (congrès uniquement)\n",
    "# - 'années' -> tente de comparer les sous-champs 111$d si présents (congrès uniquement)\n",
    "\n",
    "# Définition des fichiers exportés de IdRef et ATC/RNV pour comparaison des sous-champs. Utilisé uniquement en mode 'idref-local'\n",
    "idref_set = 'collectivités'\n",
    "idref_records_folder = \"/Users/thomas/Documents/tmp-nobackup/bcu-rnv/idref-harvest-\" + idref_set\n",
    "# Plusieurs fichiers ATC/RNV peuvent être utilisés. Attention à les identifier dans le même ordre.\n",
    "# Valeurs possibles pour atc_sets:\n",
    "# - 'personnes'\n",
    "# - 'collectivités'\n",
    "# - 'congrès'\n",
    "atc_sets = ['collectivités', 'congrès']\n",
    "atc_records_file_paths = [\"input/notices-detaillees/20241028_auth_atc_corporate_subf_a-b.tsv\",\"input/notices-detaillees/20241028_auth_atc_meeting_subf_a-d.tsv\"]\n",
    "\n",
    "# Pour limiter le chargement des fichiers IdRef (ex. pour tester), renseigner cette variable pour ne charger que les x premier fichiers.\n",
    "# Pour ne pas limiter, assigner la valeur -1\n",
    "idref_records_limit = -1\n",
    "\n",
    "# Quel caractère utiliser pour séparer les valeurs provenant de champs répétés lors de leur mapping\n",
    "multifield_join_char = '|'\n",
    "\n",
    "# Fichiers temporaires pour accélérer le traitement successif lors de la comparaison des sous-champs. Si existants, ils sont utilisés\n",
    "# en mode 'idref-local' en lieu et place des notices complètes ci-dessus.\n",
    "idref_records_extract = \"input/idref-extrait-\" + idref_set + \"-comparaison.csv\"\n",
    "\n",
    "# Nom de la colonne ajoutée\n",
    "output_colname = \"validation auto\"\n",
    "\n",
    "# Lors des comparaisons textuelles, la distance calculée sera renseignée dans cette colonne\n",
    "distance_colname = \"distance validation\"\n",
    "\n",
    "# Définit la valeur de distance (rapportée à la longueur de la forme source) à partir de laquelle on considère qu'il y a une différence.\n",
    "distance_limit = 0.15\n",
    "\n",
    "# Ajoute une colonne avec des détails de comparaison, pour débogger\n",
    "debug_column = True\n",
    "\n",
    "# Définition des colonnes contenant les formes sources et cible à comparer\n",
    "source_form_colname = \"forme principale source\"\n",
    "target_form_colname = \"forme principale cible\"\n",
    "align_type_colname = \"décision d'alignement\"\n",
    "target_colname = \"réservoir cible\"\n",
    "target_candidatenr_colname = \"nombre de candidats\"\n",
    "idref_id_colname = \"id cible\"\n",
    "atc_id_colname = \"id source\"\n",
    "\n",
    "# Vérifier que tous les fichiers existent vraiment avant de continuer\n",
    "all_files = []\n",
    "for variable in [input_file_path, atc_records_file_paths]:\n",
    "    if isinstance(variable, list):\n",
    "        all_files.extend(variable)\n",
    "    else:\n",
    "        all_files.append(variable)\n",
    "\n",
    "for file in all_files:\n",
    "    if file and not os.path.isfile(file):\n",
    "        print(\"ATTENTION le fichier suivant n'existe pas: \",file)\n",
    "\n",
    "# Le fichier à vérifier est chargé dans une dataframe\n",
    "df = pd.read_csv(input_file_path, sep='\\t', dtype = str)\n",
    "print(df.shape)\n",
    "\n",
    "# Pour la comparaison, on retire les types d'alignements ignorés ainsi que les non-alignements\n",
    "df_filtered = df[(df[align_type_colname].isin(valid_types)) & (df[target_colname] == 'idref')]\n",
    "df_rest = df[(~df[align_type_colname].isin(valid_types)) | (df[target_colname] != 'idref')]\n",
    "print(df_filtered.shape)\n",
    "print(df_rest.shape)\n",
    "display(df_filtered.head())\n",
    "\n",
    "df_filtered.reset_index(drop=True, inplace=True)  # Drop indexes since we're not going to use them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e298d4-d73d-449f-b73f-38f78a6f4ed7",
   "metadata": {},
   "source": [
    "## Chargement des fichiers auxiliaires\n",
    "\n",
    "Si une comparaison utilisant les notices complètes IdRef et ATC/RNV est demandée, charger ces dernières dans un dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "415ef921-effc-479f-946c-27475c3dec8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442952 notices IdRef chargées depuis input/idref-extrait-collectivités-comparaison.csv\n",
      "28746 notices ATC/RNV chargées depuis le fichier input/notices-detaillees/20241028_auth_atc_corporate_subf_a-b.tsv\n",
      "44362 notices ATC/RNV chargées depuis le fichier input/notices-detaillees/20241028_auth_atc_meeting_subf_a-d.tsv\n",
      "73108 notices ATC/RNV chargées au total.\n",
      "--- Temps écoulé pour le chargement des fichiers: 0:00:01.491597 ---\n"
     ]
    }
   ],
   "source": [
    "# Fonctions nécessaires à traiter les fichiers XML provenant d'IdRef (Marc21)\n",
    "tps_debut_chargement = datetime.now()\n",
    "\n",
    "# Chargement des fichiers individuels\n",
    "def parse_marcxml_file(file_path):\n",
    "    records = []\n",
    "    with open(file_path, 'rb') as fh:\n",
    "        marc_records = parse_xml_to_array(fh)\n",
    "        for record in marc_records:\n",
    "            if record != None:\n",
    "                record_dict = extract_record_data(record)\n",
    "                if record_dict != None:\n",
    "                    records.append(record_dict)\n",
    "    return records\n",
    "\n",
    "# Extraction des champs nécessaires\n",
    "def extract_record_data(record):\n",
    "    field_001 = record.get('001')\n",
    "    if field_001:\n",
    "        if idref_set == 'personnes' :\n",
    "            field_100 = record.get('100')\n",
    "            record_data = {\n",
    "                'idref_id' : field_001.data.replace('(IDREF)','').strip(),\n",
    "                '100a': field_100.get('a') if field_100 else None,\n",
    "                '100b': field_100.get('b') if field_100 else None,\n",
    "                '100c': field_100.get('c') if field_100 else None,\n",
    "                '100d': field_100.get('d') if field_100 else None\n",
    "            }\n",
    "        elif idref_set == 'collectivités':\n",
    "            output_110a = []\n",
    "            output_110b = []\n",
    "            output_110g = []\n",
    "            output_111a = []\n",
    "            output_111c = []\n",
    "            output_111d = []\n",
    "            output_111n = []\n",
    "            output_411a = []\n",
    "            output_411c = []\n",
    "            output_411d = []\n",
    "            output_411n = []\n",
    "            for field_110 in record.get_fields('110'):\n",
    "                output_110a.append(multifield_join_char.join(field_110.get_subfields('a')))\n",
    "                output_110b.append(multifield_join_char.join(field_110.get_subfields('b')))\n",
    "                output_110g.append(multifield_join_char.join(field_110.get_subfields('g')))\n",
    "            for field_111 in record.get_fields('111'):\n",
    "                output_111a.append(multifield_join_char.join(field_111.get_subfields('a')))\n",
    "                output_111c.append(multifield_join_char.join(field_111.get_subfields('c')))\n",
    "                output_111d.append(multifield_join_char.join(field_111.get_subfields('d')))\n",
    "                output_111n.append(multifield_join_char.join(field_111.get_subfields('n')))\n",
    "            for field_411 in record.get_fields('411'):\n",
    "                output_411a.append(multifield_join_char.join(field_411.get_subfields('a')))\n",
    "                output_411c.append(multifield_join_char.join(field_411.get_subfields('c')))\n",
    "                output_411d.append(multifield_join_char.join(field_411.get_subfields('d')))\n",
    "                output_411n.append(multifield_join_char.join(field_411.get_subfields('n')))\n",
    "\n",
    "            record_data = {\n",
    "                'idref_id' : field_001.data.replace('(IDREF)','').strip(),\n",
    "                '110a': multifield_join_char.join(output_110a) if output_110a else None,\n",
    "                '110b': multifield_join_char.join(output_110b) if output_110b else None,\n",
    "                '110g': multifield_join_char.join(output_110g) if output_110g else None,\n",
    "                '111a': multifield_join_char.join(output_111a) if output_111a else None,\n",
    "                '111c': multifield_join_char.join(output_111c) if output_111c else None,\n",
    "                '111d': multifield_join_char.join(output_111d) if output_111d else None,\n",
    "                '111n': multifield_join_char.join(output_111n) if output_111n else None,\n",
    "                '411a': multifield_join_char.join(output_411a) if output_411a else None,\n",
    "                '411c': multifield_join_char.join(output_411c) if output_411c else None,\n",
    "                '411d': multifield_join_char.join(output_411d) if output_411d else None,\n",
    "                '411n': multifield_join_char.join(output_411n) if output_411n else None\n",
    "                }\n",
    "        else:\n",
    "            return None\n",
    "        return record_data\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Chargement des fichiers du dossier IdRef\n",
    "def load_marcxml_files_from_folder(folder_path, limit, status_display):\n",
    "    all_records = []\n",
    "    \n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.xml'): \n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            records = parse_marcxml_file(file_path)\n",
    "            all_records.extend(records)\n",
    "        status_display.value += 1\n",
    "        if (limit > 0 and status_display.value == limit):\n",
    "            break\n",
    "    \n",
    "    # Convert list of records to DataFrame\n",
    "    df = pd.DataFrame(all_records)\n",
    "    return df\n",
    "\n",
    "# Chargement des fichiers auxiliaires si on a choisi le type de validation 'idref-local'\n",
    "if 'idref-local' in validations:\n",
    "    \n",
    "    # Si un fichier CSV a été fourni (l'extraction a déjà été faite), charger les notices depuis ce fichier\n",
    "    if idref_records_extract and os.path.isfile(idref_records_extract):\n",
    "        idRef_df = pd.read_csv(idref_records_extract, dtype = str)\n",
    "        print(f\"{len(idRef_df.index)} notices IdRef chargées depuis {idref_records_extract}\")\n",
    "    else:\n",
    "        # Sinon, on prend une grande respiration et on charge tous les fichiers IdRef dans un dataframe\n",
    "        \n",
    "        # Affiche une barre de progression\n",
    "        if idref_records_limit > 0:\n",
    "            num_files = idref_records_limit\n",
    "        else:\n",
    "            num_files = sum(1 for entry in os.scandir(idref_records_folder) if entry.is_file() and entry.name.endswith('.xml'))\n",
    "        barre_attente_idRef = IntProgress(min=1, max=num_files, description=\"Chargement des fichiers IdRef: \", style={'description_width':'initial'},layout={'width':'80%'})\n",
    "        display(barre_attente_idRef)\n",
    "        \n",
    "        idRef_df = load_marcxml_files_from_folder(idref_records_folder, idref_records_limit, barre_attente_idRef)\n",
    "        \n",
    "        # Une fois le chargement terminé, on écrit le résultat dans un fichier CSV\n",
    "        if idref_records_extract:\n",
    "            idRef_df.to_csv(idref_records_extract, encoding=\"UTF-8\", index=False)\n",
    "    \n",
    "        print(f\"{len(idRef_df.index)} notices IdRef chargées depuis export OAI IdRef dans {idref_records_folder}\")\n",
    "    \n",
    "    # Utiliser l'identifiant IdRef comme index (pour accélérer les requêtes)\n",
    "    idRef_df.set_index('idref_id', inplace=True)\n",
    "    # Retirer les éventuels doublons\n",
    "    idRef_df = idRef_df[~idRef_df.index.duplicated(keep='first')]\n",
    "    \n",
    "    # Chargement des fichiers ATC/RNV\n",
    "    atc_df_list = []\n",
    "    for file_index, atc_records_file_path in enumerate(atc_records_file_paths):\n",
    "        if atc_records_file_path and os.path.isfile(atc_records_file_path):\n",
    "            atc_df_toadd = pd.read_csv(atc_records_file_path, sep='\\t', dtype = str)\n",
    "            atc_set = atc_sets[file_index]\n",
    "            # Extraire le contenu des sous-champs dans des colonnes distinctes (en enlevant les dernières virgules, si présentes)\n",
    "            if atc_set == 'personnes':\n",
    "                atc_df_toadd['100a'] = atc_df_toadd['subfields_content_for_tag2'].str.extract(r'\\$\\$a ([^$]+)')[0].str.replace(r'[,\\s]+$', '', regex=True)\n",
    "                atc_df_toadd['100b'] = atc_df_toadd['subfields_content_for_tag2'].str.extract(r'\\$\\$b ([^$]+)')[0].str.replace(r'[,\\s]+$', '', regex=True)\n",
    "                atc_df_toadd['100c'] = atc_df_toadd['subfields_content_for_tag2'].str.extract(r'\\$\\$c ([^$]+)')[0].str.replace(r'[,\\s]+$', '', regex=True)\n",
    "                atc_df_toadd['100d'] = atc_df_toadd['subfields_content_for_tag2'].str.extract(r'\\$\\$d ([^$]+)')[0].str.replace(r'[,\\s]+$', '', regex=True)\n",
    "            if atc_set == 'congrès':\n",
    "                # Séparer les sous-champs de tags 110 et 111 - ne semble pas nécessaire\n",
    "                #atc_df_toadd['110_subfields'] = atc_df_toadd.apply(lambda row: row['subfields_content_for_tag2'] if row['tag'] == '110' else None, axis=1)\n",
    "                #atc_df_toadd['111_subfields'] = atc_df_toadd.apply(lambda row: row['subfields_content_for_tag2'] if row['tag'] == '111' else None, axis=1)\n",
    "                # Regrouper par id pour éviter les doublons. Par la même, on utilise également l'identifiant comme index\n",
    "                atc_df_toadd = atc_df_toadd.groupby('id').agg({'repo_id': 'first', 'subfields_content_for_tag2': 'first', 'tag':'first'})\n",
    "            if atc_set == 'collectivités':\n",
    "                atc_df_toadd = atc_df_toadd.groupby('id').agg({'repo_id': 'first', 'subfields_content_for_tag2': 'first'})\n",
    "            atc_df_toadd['type'] = atc_set\n",
    "            atc_df_list.append(atc_df_toadd)\n",
    "            print(f\"{len(atc_df_toadd.index)} notices ATC/RNV chargées depuis le fichier {atc_records_file_path}\")\n",
    "        else:\n",
    "            print('Attention! Le fichier des notices ATC/RNV est manquant!')\n",
    "    atc_df = pd.concat(atc_df_list)\n",
    "    print(f\"{len(atc_df.index)} notices ATC/RNV chargées au total.\")\n",
    "\n",
    "tps_fin_chargement = datetime.now()\n",
    "print(\"--- Temps écoulé pour le chargement des fichiers: %s ---\" % format(tps_fin_chargement - tps_debut_chargement))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818c4c80-3a91-416b-a0b2-127d0a24819d",
   "metadata": {},
   "source": [
    "## Définition des fonctions utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29825d8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fonction de comparaison des dates\n",
    "def date_compare(source_date,target_date):\n",
    "    source_date = str(source_date)\n",
    "    target_date = str(target_date)\n",
    "    # Ignorer les points d'interrogation\n",
    "    source_date = source_date.replace('?','')\n",
    "    target_date = target_date.replace('?','')\n",
    "    # Retirer le zéro en début de date\n",
    "    if source_date.startswith('0'):\n",
    "        source_date = source_date[1:0]\n",
    "    if target_date.startswith('0'):\n",
    "        target_date = target_date[1:0]\n",
    "    #print(\"Source: \" + source_date)\n",
    "    #print(\"Target: \" + target_date)\n",
    "    # Si l'une des dates à comparer est vide, on passe\n",
    "    if ((source_date == '') | (target_date == '')):\n",
    "        return False\n",
    "    # Si l'une des dates comporte des points, ne comparer que les chiffres entre eux\n",
    "    if (('.' in source_date) | ('.' in target_date)):\n",
    "        #print('Comparaison avec points: ' + source_date + ' et ' + target_date)\n",
    "        for char in range(0,len(source_date)):\n",
    "            if ((source_date[char] != '.') & (target_date[char] != '.') & (source_date[char] != target_date[char])):\n",
    "                #print('Je pense que ' + source_date[char] + ' != ' + target_date[char])\n",
    "                return True\n",
    "        return False\n",
    "    if (source_date != target_date):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Expression régulière pour trouver les dates\n",
    "date_pattern = r'(?:ca\\.|fl\\.)?([0-9\\.]{4}|\\?)-?([0-9\\.]{4}|\\?)?'\n",
    "\n",
    "# Vérification des auteurs-titre\n",
    "\n",
    "idref_base_url = 'https://idref.fr/'\n",
    "\n",
    "# Fonction utile pour déterminer si un champ MARC existe\n",
    "def contains_tag(data, tag_value):\n",
    "    return any(record['tag'] == tag_value for record in data)\n",
    "\n",
    "# Fonction pour extraire certains champs d'une notice IdRef\n",
    "def get_idref_fields(notice,fields):\n",
    "    output_fields = []\n",
    "    for field in fields:\n",
    "        try:\n",
    "            # On compare les valeurs à elles-mêmes pour s'assurer qu'elles ne sont pas \"NaN\"\n",
    "            if notice[field] == notice[field]:\n",
    "                output_fields = output_fields + notice[field].split(multifield_join_char)\n",
    "        except (KeyError, TypeError) as e:\n",
    "            # Ignorer s'il manque un des champs\n",
    "            pass\n",
    "    return output_fields\n",
    "            \n",
    "\n",
    "# Fonctions pour comparer toutes les combinaisons de nombres\n",
    "def number_compare(num1, num2):\n",
    "    try:\n",
    "        return abs(int(num1)-int(num2))\n",
    "    except ValueError as e:\n",
    "        # L'une des valeurs ne semble pas être un nombre, on l'ignore\n",
    "        return None\n",
    "\n",
    "def find_number_match(array1, array2):\n",
    "    combinations = itertools.product(array1,array2)\n",
    "    combined_results = [number_compare(x, y) for x, y in combinations]\n",
    "    if min(combined_results) == 0:\n",
    "        # En tous cas une des comparaisons a retourné zéro, donc c'est un match\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Fonction pour comparer toutes les combinaisons de dates de congrès\n",
    "def find_date_match(array1, array2):\n",
    "    combinations = itertools.product(array1,array2)\n",
    "    # La fonction date_compare retourne False si la date correspond, donc on inverse\n",
    "    combined_results = [not(date_compare(x, y)) for x, y in combinations]\n",
    "    if min(combined_results) == 0:\n",
    "        # En tous cas une des comparaisons a été positive, donc c'est un match\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Fonction pour calculer la distance minimale sur toutes les combinaisons de termes\n",
    "def find_minimal_distance(array1, array2):\n",
    "    # On calcule la distance pour chaque combinaison, en ne conservant que la partie avant la virgule (en général plus significative)\n",
    "    combinations = itertools.product([text.split(',')[0].strip() for text in array1], [text.split(',')[0].strip() for text in array2])\n",
    "    combined_results = [jellyfish.levenshtein_distance(x, y)/len(x) for x, y in combinations]\n",
    "    return min(combined_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a7eb14-bbb9-4acc-8fce-747a795f6acb",
   "metadata": {},
   "source": [
    "## Moulinette de validation\n",
    "C'est là que tout se passe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6fefac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c757887ac246aea5d8dd118818b2e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=1, description=\"État d'avancement: \", layout=Layout(width='80%'), max=10138, min=1, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>réservoir source</th>\n",
       "      <th>id source</th>\n",
       "      <th>forme principale source</th>\n",
       "      <th>arbitre</th>\n",
       "      <th>date d'arbitrage</th>\n",
       "      <th>niveau de confiance</th>\n",
       "      <th>commentaire</th>\n",
       "      <th>décision d'alignement</th>\n",
       "      <th>nombre de candidats</th>\n",
       "      <th>score algo max</th>\n",
       "      <th>...</th>\n",
       "      <th>réservoir cible 2</th>\n",
       "      <th>id cible 2</th>\n",
       "      <th>forme principale cible 2</th>\n",
       "      <th>type de cible 3</th>\n",
       "      <th>réservoir cible 3</th>\n",
       "      <th>id cible 3</th>\n",
       "      <th>forme principale cible 3</th>\n",
       "      <th>debug</th>\n",
       "      <th>validation auto</th>\n",
       "      <th>distance validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rnv-nz-auth-atc</td>\n",
       "      <td>981023280158302851</td>\n",
       "      <td>Bibliothèque municipale (Angers)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rnv-nz-auth-atc</td>\n",
       "      <td>981023280248402851</td>\n",
       "      <td>Verein Ernst Mach (Wien)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9239130434782609</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rnv-nz-auth-atc</td>\n",
       "      <td>981023280266802851</td>\n",
       "      <td>Musée national des monuments français (Paris)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rnv-nz-auth-atc</td>\n",
       "      <td>981023280267302851</td>\n",
       "      <td>Università di Roma. Istituto di studi bizantin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9818840579710144</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Match sur une des formes |</td>\n",
       "      <td>OK (levenshtein)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rnv-nz-auth-atc</td>\n",
       "      <td>981023280267902851</td>\n",
       "      <td>Musée de l'Institut du monde arabe (Paris)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  réservoir source           id source  \\\n",
       "0  rnv-nz-auth-atc  981023280158302851   \n",
       "1  rnv-nz-auth-atc  981023280248402851   \n",
       "2  rnv-nz-auth-atc  981023280266802851   \n",
       "3  rnv-nz-auth-atc  981023280267302851   \n",
       "4  rnv-nz-auth-atc  981023280267902851   \n",
       "\n",
       "                             forme principale source arbitre date d'arbitrage  \\\n",
       "0                 Bibliothèque municipale (Angers)       NaN              NaN   \n",
       "1                         Verein Ernst Mach (Wien)       NaN              NaN   \n",
       "2    Musée national des monuments français (Paris)       NaN              NaN   \n",
       "3  Università di Roma. Istituto di studi bizantin...     NaN              NaN   \n",
       "4       Musée de l'Institut du monde arabe (Paris)       NaN              NaN   \n",
       "\n",
       "  niveau de confiance commentaire décision d'alignement nombre de candidats  \\\n",
       "0                 NaN         NaN                  auto                   1   \n",
       "1                 NaN         NaN                  auto                   1   \n",
       "2                 NaN         NaN                  auto                   1   \n",
       "3                 NaN         NaN                  auto                   1   \n",
       "4                 NaN         NaN                  auto                   1   \n",
       "\n",
       "       score algo max  ... réservoir cible 2 id cible 2  \\\n",
       "0                 1.0  ...               NaN        NaN   \n",
       "1  0.9239130434782609  ...               NaN        NaN   \n",
       "2                 1.0  ...               NaN        NaN   \n",
       "3  0.9818840579710144  ...               NaN        NaN   \n",
       "4                 1.0  ...               NaN        NaN   \n",
       "\n",
       "  forme principale cible 2 type de cible 3 réservoir cible 3 id cible 3  \\\n",
       "0                      NaN             NaN               NaN        NaN   \n",
       "1                      NaN             NaN               NaN        NaN   \n",
       "2                      NaN             NaN               NaN        NaN   \n",
       "3                      NaN             NaN               NaN        NaN   \n",
       "4                      NaN             NaN               NaN        NaN   \n",
       "\n",
       "  forme principale cible 3                        debug   validation auto  \\\n",
       "0                      NaN                                            NaN   \n",
       "1                      NaN                                            NaN   \n",
       "2                      NaN                                            NaN   \n",
       "3                      NaN  Match sur une des formes |   OK (levenshtein)   \n",
       "4                      NaN                                            NaN   \n",
       "\n",
       "  distance validation  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 0.0  \n",
       "4                 NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'appels d'API: 0 (0% des alignements)\n",
      "--- Temps écoulé pour la comparaison des alignements: 0:00:03.070173 ---\n"
     ]
    }
   ],
   "source": [
    "# Affiche une barre de progression\n",
    "numrows = df_filtered.shape[0]\n",
    "barre_attente = IntProgress(min=1, max=numrows, description=\"État d'avancement: \", style={'description_width':'initial'},layout={'width':'80%'})\n",
    "display(barre_attente)\n",
    "update_interval = 100 # Ne pas rafraîchir la barre trop vite sinon ça bugge l'affichage\n",
    "\n",
    "if not(output_in_place):\n",
    "    wrong_dates = []\n",
    "    wrong_types = []\n",
    "    wrong_forms = []\n",
    "    misc_errors = []\n",
    "\n",
    "nb_api_calls = 0\n",
    "\n",
    "tps_debut_moulinette = datetime.now()\n",
    "\n",
    "for index, row in df_filtered.iterrows():\n",
    "    if not ((row[source_form_colname] == '') | (row[target_form_colname] == '') | pd.isnull(row[source_form_colname]) | pd.isnull(row[target_form_colname])):\n",
    "\n",
    "        source_dates = ''\n",
    "        target_dates = ''\n",
    "        verif_dates = False\n",
    "\n",
    "        source_term = ''\n",
    "        target_term = ''\n",
    "\n",
    "        notice_idref = None\n",
    "        notice_atc = None\n",
    "\n",
    "        distance = None\n",
    "        valid_score = 0\n",
    "\n",
    "        debug_output = ''\n",
    "        source_type = ''\n",
    "        \n",
    "        # Procéder à la validation en utilisant les notices complètes IdRef et ATC/RNV si demandé\n",
    "        \n",
    "        if 'idref-local' in validations:\n",
    "            # La validation ne peut se faire que si les notices complètes existent\n",
    "            try:\n",
    "                notice_idref = idRef_df.loc[row[idref_id_colname]]\n",
    "            except (KeyError, TypeError) as e:\n",
    "                # Ignorer cette ligne s'il manque une des données requises\n",
    "                pass\n",
    "            try:\n",
    "                notice_atc = atc_df.loc[row[atc_id_colname]]\n",
    "                source_type = notice_atc['type']\n",
    "            except (KeyError, TypeError) as e:\n",
    "                # Ignorer cette ligne s'il manque une des données requises\n",
    "                pass\n",
    "            if 'dates' in validations:\n",
    "                # Extraction des dates de vie pour les personnes\n",
    "                try:\n",
    "                    source_dates = re.findall(date_pattern, notice_atc['100d'])\n",
    "                except (KeyError, TypeError) as e:\n",
    "                    # Ignorer cette ligne s'il manque une des données requises\n",
    "                    pass\n",
    "                try:\n",
    "                    target_dates = re.findall(date_pattern, notice_idref['100d'])\n",
    "                except (KeyError, TypeError) as e:\n",
    "                    # Ignorer cette ligne s'il manque une des données requises\n",
    "                    pass\n",
    "            if ('similarité' in validations) and (idref_set == 'personnes'):\n",
    "                # Extraction des formes pour la comparaison de similarité, pour les personnes\n",
    "                try:\n",
    "                    source_term = notice_atc['100a']\n",
    "                except (KeyError, TypeError) as e:\n",
    "                    # Ignorer cette ligne s'il manque une des données requises\n",
    "                    pass\n",
    "                try:\n",
    "                    target_term = notice_idref['100a']\n",
    "                except (KeyError, TypeError) as e:\n",
    "                    # Ignorer cette ligne s'il manque une des données requises\n",
    "                    pass\n",
    "            if 'professions' in validations:\n",
    "                # Comparaison des \"professions\", pour les personnes\n",
    "                try:\n",
    "                    source_prof = notice_atc['100c']\n",
    "                    target_prof = notice_idref['100c']\n",
    "                    distance_prof = jellyfish.levenshtein_distance(source_prof,target_prof)/len(source_prof)\n",
    "                    if distance_prof > distance_limit:\n",
    "                        if (output_in_place):\n",
    "                            df_filtered.loc[index, output_colname] = \"Vérifier professions\"\n",
    "                            df_filtered.loc[index, distance_colname] = distance_prof\n",
    "                    elif (output_in_place):\n",
    "                            df_filtered.loc[index, output_colname] = \"OK ($$c)\"\n",
    "                except (KeyError, TypeError) as e:\n",
    "                    # Ignorer cette validation s'il manque une des données requises\n",
    "                    pass\n",
    "            if 'lieux' in validations:\n",
    "                # Comparaison de type lieux\n",
    "                try:\n",
    "                    if source_type == 'congrès':\n",
    "                        # Cas d'un congrès\n",
    "                        source_locations = re.findall(r'\\$\\$c ([^$^)]+)',notice_atc['subfields_content_for_tag2'])\n",
    "                        target_locations = get_idref_fields(notice_idref, ['111c', '411c'])\n",
    "                        if (len(source_locations)) > 0 and (len(target_locations) > 0):\n",
    "                            if find_minimal_distance(source_locations,target_locations) <= distance_limit:\n",
    "                                # En tous cas une des comparaisons de lieux semble indiquer un match, on donne un bon score\n",
    "                                valid_score += 10\n",
    "                                if debug_column:\n",
    "                                    debug_output = debug_output + f\"Match sur lieu de congrès | \"\n",
    "                except (KeyError, TypeError, ValueError) as e:\n",
    "                    # Ignorer cette validation s'il manque une des données requises\n",
    "                    pass\n",
    "            if 'numéros' in validations:\n",
    "                # Comparaison de numéro de congrès\n",
    "                try:\n",
    "                    if source_type == 'congrès':\n",
    "                        source_congressnr = re.findall(r'\\$\\$n \\(?(\\d+)',notice_atc['subfields_content_for_tag2'])\n",
    "                        target_congressnr = get_idref_fields(notice_idref, ['111n', '411n'])\n",
    "                        if (len(source_congressnr)) > 0 and (len(target_congressnr) > 0):\n",
    "                            if find_number_match(source_congressnr,target_congressnr):\n",
    "                                # En tous cas une des comparaisons de numéros semble indiquer un match, on donne un bon score\n",
    "                                valid_score += 10\n",
    "                                if debug_column:\n",
    "                                    debug_output = debug_output + f\"Match sur numéro de congrès | \"\n",
    "                except (KeyError, TypeError, ValueError) as e:\n",
    "                    # Ignorer cette validation s'il manque une des données requises\n",
    "                    pass     \n",
    "            if 'années' in validations:\n",
    "                # Comparaison de date de congrès\n",
    "                try:\n",
    "                    if source_type == 'congrès':\n",
    "                        source_congressdate = re.findall(r'\\$\\$d \\(?(\\d+)',notice_atc['subfields_content_for_tag2'])\n",
    "                        target_congressdate = get_idref_fields(notice_idref, ['111d', '411d'])\n",
    "                        if (len(source_congressdate)) > 0 and (len(target_congressdate) > 0):\n",
    "                            if find_number_match(source_congressdate,target_congressdate):\n",
    "                                # En tous cas une des comparaisons de numéros semble indiquer un match, on donne un bon score\n",
    "                                valid_score += 10\n",
    "                                if debug_column:\n",
    "                                    debug_output = debug_output + f\"Match sur date de congrès | \"\n",
    "                except (KeyError, TypeError, ValueError) as e:\n",
    "                    # Ignorer cette validation s'il manque une des données requises\n",
    "                    pass  \n",
    "            if 'similarité' in validations and (idref_set != 'personnes'):\n",
    "                # Comparaison de forme principale pour collectivités et congrès\n",
    "                try:\n",
    "                    if source_type == 'congrès':\n",
    "                        source_congressterms = re.findall(r'\\$\\$a ([^$]+)',notice_atc['subfields_content_for_tag2'])\n",
    "                        target_congressterms = get_idref_fields(notice_idref, ['110a', '110b', '111a', '411a'])\n",
    "                        if (len(source_congressterms)) > 0 and (len(target_congressterms) > 0):\n",
    "                            if find_minimal_distance(source_congressterms,target_congressterms) <= distance_limit:\n",
    "                                # En tous cas une des comparaisons de lieux semble indiquer un match, on donne un bon score\n",
    "                                valid_score += 10\n",
    "                                if debug_column:\n",
    "                                    debug_output = debug_output + f\"Match sur titre de congrès | \"\n",
    "                    elif source_type == 'collectivités':\n",
    "                        source_foundterms = re.findall(r'\\$\\$a ([^$]+)\\$\\$b ([^$]+)$',notice_atc['subfields_content_for_tag2'])\n",
    "                        source_prefterms = [item for match in source_foundterms for item in match]\n",
    "                        target_prefterms = get_idref_fields(notice_idref, ['110a', '110b'])\n",
    "                        if (len(source_prefterms)) > 0 and (len(target_prefterms) > 0):\n",
    "                            min_distance = find_minimal_distance(source_prefterms,target_prefterms)\n",
    "                            if min_distance <= distance_limit:\n",
    "                                # En tous cas une des comparaisons de termes semble indiquer un match, on considère que c'est correct\n",
    "                                if (output_in_place):\n",
    "                                    df_filtered.loc[index, output_colname] = \"OK (levenshtein)\"\n",
    "                                    df_filtered.loc[index, distance_colname] = min_distance\n",
    "                                if debug_column:\n",
    "                                    debug_output = debug_output + f\"Match sur une des formes | \"\n",
    "                            else:\n",
    "                                # Aucune comparaison n'est concluante, on considère qu'il faut vérifier\n",
    "                                if (output_in_place):\n",
    "                                    df_filtered.loc[index, output_colname] = \"Vérifier forme principale\"\n",
    "                                    df_filtered.loc[index, distance_colname] = min_distance\n",
    "                except (KeyError, TypeError, ValueError) as e:\n",
    "                    # Ignorer cette validation s'il manque une des données requises\n",
    "                    pass  \n",
    "\n",
    "        # Pour les congrès, si au moins une des validations est OK, on considère que c'est correct\n",
    "        if (source_type == 'congrès') and (valid_score > 10):\n",
    "            if (output_in_place):\n",
    "                df_filtered.loc[index, output_colname] = f\"OK (congrès score {str(valid_score)})\"\n",
    "        if (source_type == 'congrès') and (valid_score < 10):\n",
    "            if (output_in_place):\n",
    "                df_filtered.loc[index, output_colname] = \"Vérifier congrès\"\n",
    "\n",
    "        \n",
    "        # Les comparaisons suivantes ne sont utiles que pour les notices de type \"personnes\"\n",
    "        if 'personnes' in validations:\n",
    "            # Extraire les dates de la forme principale si on ne les a pas trouvées dans les sous-champs'\n",
    "            if len(source_dates) < 1:\n",
    "                source_dates = re.findall(date_pattern, row[source_form_colname])\n",
    "            if len(target_dates) < 1:\n",
    "                target_dates = re.findall(date_pattern, row[target_form_colname])\n",
    "    \n",
    "            if debug_column:\n",
    "                debug_output = debug_output + f\"Dates {source_dates} et {target_dates} | \"\n",
    "            \n",
    "            # Validation de date si elles sont présentes des deux côtés et si demandé\n",
    "            if ((len(source_dates) > 0) and (len(target_dates) > 0) and ('dates' in validations)):\n",
    "                if (date_compare(source_dates[0][0],target_dates[0][0]) | date_compare(source_dates[0][1],target_dates[0][1])):\n",
    "                    # Cas potentiel de dates qui ne correspondent pas\n",
    "                    if (output_in_place):\n",
    "                        df_filtered.loc[index, output_colname] = \"Vérifier dates\"\n",
    "                    else:\n",
    "                        wrong_dates.append(row)\n",
    "                else:\n",
    "                    # Les dates semblent correspondre, utiliser cette information pour valider l'alignement\n",
    "                    verif_dates = True\n",
    "                    df_filtered.loc[index, output_colname] = \"OK (dates)\"\n",
    "    \n",
    "            \n",
    "            # Utiliser les formes simples pour la similarité textuelle (sans chiffres et signes de ponctuation) si on n'a pas pu extraire le sous-champ $a\n",
    "            if len(source_term) < 1:\n",
    "                source_term = re.sub(r'[\\d,-.\\?()]', '', row[source_form_colname]).strip()\n",
    "    \n",
    "            if len(target_term) < 1:\n",
    "                target_term = re.sub(r'[\\d,-.\\?()]', '', row[target_form_colname]).strip()\n",
    "    \n",
    "            if debug_column:\n",
    "                debug_output = debug_output + f\"Comparaison entre {source_term} et {target_term} | \"\n",
    "            \n",
    "            # Calculer la similarité textuelle si demandé\n",
    "            if (len(source_term) > 0) and (len(target_term) > 0) and ('similarité' in validations):\n",
    "                distance = jellyfish.levenshtein_distance(source_term,target_term)/len(source_term)\n",
    "                if debug_column:\n",
    "                    debug_output = debug_output + f\"distance: {str(distance)} | \"\n",
    "    \n",
    "            if (distance is not None and distance > distance_limit and not(verif_dates)):\n",
    "                # Signaler comme erreur potentielle sauf si validé par les dates\n",
    "                if (output_in_place):\n",
    "                    df_filtered.loc[index, output_colname] = \"Vérifier forme principale\"\n",
    "                    df_filtered.loc[index, distance_colname] = distance\n",
    "                else:\n",
    "                    wrong_forms.append(row)\n",
    "            elif (distance is not None and distance <= distance_limit and not(verif_dates) and output_in_place):\n",
    "                    df_filtered.loc[index, output_colname] = \"OK (levenshtein)\"\n",
    "                    df_filtered.loc[index, distance_colname] = distance\n",
    "\n",
    "        \n",
    "        # Vérifier si la notice IdRef vers laquelle on aligne est de type auteur-titre, seulement si demandé\n",
    "        if 'auteur-titre' in validations:\n",
    "            if notice_idref is None:\n",
    "                # Si la notice cible n'est pas disponible localement, il ne s'agit probablement pas d'une notice de type auteur\n",
    "                # Faire un appel d'API pour en avoir le coeur net.\n",
    "                # ATTENTION cette étape est très coûteuse en temps\n",
    "                idref_id = row[idref_id_colname]\n",
    "                url = idref_base_url + str(idref_id) + '.json'\n",
    "                #print(\"Appel d'API pour \" + str(idref_id))\n",
    "                nb_api_calls += 1\n",
    "                # Appel d'API\n",
    "                idref_result = requests.get(url)\n",
    "                if (idref_result.status_code == 200):\n",
    "                    # Identifier si le résultat contient un champ 240\n",
    "                    if contains_tag(idref_result.json()['record']['datafield'], 240):\n",
    "                        if (output_in_place):\n",
    "                            df_filtered.loc[index, output_colname] = \"Cible de type auteur-titre\"\n",
    "                        else:\n",
    "                            wrong_types.append(row)\n",
    "                else:\n",
    "                    # Erreur de requête API\n",
    "                    if (output_in_place):\n",
    "                        df_filtered.loc[index, output_colname] = \"Erreur de requête API IdRef. Code:\" + str(idref_result.status_code)\n",
    "                    else:\n",
    "                        misc_errors.append(row)\n",
    "    \n",
    "    else:\n",
    "        # Il manque un des champs à comparer, autre erreur\n",
    "        if (output_in_place):\n",
    "            df_filtered.loc[index, output_colname] = \"Erreur de validation\"\n",
    "        else:\n",
    "            misc_errors.append(row)\n",
    "    \n",
    "    if debug_column:\n",
    "        df_filtered.loc[index, \"debug\"] = debug_output\n",
    "\n",
    "    if index % update_interval == 0:\n",
    "        barre_attente.value = index\n",
    "\n",
    "display(df_filtered.head())\n",
    "\n",
    "tps_fin_moulinette = datetime.now()\n",
    "print(\"Nombre d'appels d'API: \" + str(nb_api_calls) + \" (\" + str(round(nb_api_calls/numrows*100)) + \"% des alignements)\")\n",
    "print(\"--- Temps écoulé pour la comparaison des alignements: %s ---\" % format(tps_fin_moulinette - tps_debut_moulinette))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff07abd-af61-4e38-b7e7-a1dc7b70dd5e",
   "metadata": {},
   "source": [
    "## Exports des fichiers de résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1745443-8bcd-4477-a546-dfc4f47a1373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10138, 26)\n",
      "(80325, 26)\n",
      "--- Temps écoulé pour sauvegarder les fichiers: 0:00:36.819741 ---\n",
      "--- Temps total écoulé: 0:13:03.354703 ---\n"
     ]
    }
   ],
   "source": [
    "tps_debut_sauvegarde = datetime.now()\n",
    "\n",
    "if not(output_in_place):\n",
    "    wrong_dates_df = pd.DataFrame(wrong_dates)\n",
    "    wrong_forms_df = pd.DataFrame(wrong_forms)\n",
    "    misc_errors_df = pd.DataFrame(misc_errors)\n",
    "\n",
    "    wrong_dates_df.to_excel(output_file_root + \"_dates.xlsx\",index=False)\n",
    "    wrong_forms_df.to_excel(output_file_root + \"_formes.xlsx\",index=False)\n",
    "    misc_errors_df.to_excel(output_file_root + \"_erreurs.xlsx\",index=False)\n",
    "else:\n",
    "    print(df_filtered.shape)\n",
    "    # Combiner le fichier filtré qui a été validé avec les alignements retirés au début\n",
    "    df_output = pd.concat([df_filtered,df_rest])\n",
    "    print(df_output.shape)\n",
    "    df_output.to_excel(output_file_root + \"_tout.xlsx\",index=False)\n",
    "\n",
    "tps_fin_sauvegarde = datetime.now()\n",
    "print(\"--- Temps écoulé pour sauvegarder les fichiers: %s ---\" % format(tps_fin_sauvegarde - tps_debut_sauvegarde))\n",
    "print(\"--- Temps total écoulé: %s ---\" % format(tps_fin_sauvegarde - tps_debut_chargement))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
