{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68c5225c-a829-4868-af60-ca7c95326929",
   "metadata": {},
   "source": [
    "## Chargement des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e577869",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19195, 23)\n",
      "(10416, 23)\n",
      "(8779, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>réservoir source</th>\n",
       "      <th>id source</th>\n",
       "      <th>forme principale source</th>\n",
       "      <th>arbitre</th>\n",
       "      <th>date d'arbitrage</th>\n",
       "      <th>niveau de confiance</th>\n",
       "      <th>commentaire</th>\n",
       "      <th>décision d'alignement</th>\n",
       "      <th>nombre de candidats</th>\n",
       "      <th>score algo max</th>\n",
       "      <th>...</th>\n",
       "      <th>id cible</th>\n",
       "      <th>forme principale cible</th>\n",
       "      <th>type de cible 2</th>\n",
       "      <th>réservoir cible 2</th>\n",
       "      <th>id cible 2</th>\n",
       "      <th>forme principale cible 2</th>\n",
       "      <th>type de cible 3</th>\n",
       "      <th>réservoir cible 3</th>\n",
       "      <th>id cible 3</th>\n",
       "      <th>forme principale cible 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rnv</td>\n",
       "      <td>009950613</td>\n",
       "      <td>Moussorgski, Modeste</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9742324561403508</td>\n",
       "      <td>...</td>\n",
       "      <td>050121960</td>\n",
       "      <td>Musorgskij, Modest Petrovič 1839-1881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rnv</td>\n",
       "      <td>009950616</td>\n",
       "      <td>Auric, Georges</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>02807808X</td>\n",
       "      <td>Auric, Georges 1899-1983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rnv</td>\n",
       "      <td>009950619</td>\n",
       "      <td>Milhaud, Darius</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>027029549</td>\n",
       "      <td>Milhaud, Darius 1892-1974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rnv</td>\n",
       "      <td>009950620</td>\n",
       "      <td>Poulenc, Francis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>030260655</td>\n",
       "      <td>Poulenc, Francis 1899-1963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rnv</td>\n",
       "      <td>009950621</td>\n",
       "      <td>Tailleferre, Germaine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>033067414</td>\n",
       "      <td>Tailleferre, Germaine 1892-1983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   réservoir source  id source  forme principale source arbitre  \\\n",
       "5               rnv  009950613   Moussorgski, Modeste       NaN   \n",
       "6               rnv  009950616         Auric, Georges       NaN   \n",
       "8               rnv  009950619        Milhaud, Darius       NaN   \n",
       "9               rnv  009950620       Poulenc, Francis       NaN   \n",
       "10              rnv  009950621  Tailleferre, Germaine       NaN   \n",
       "\n",
       "   date d'arbitrage niveau de confiance commentaire décision d'alignement  \\\n",
       "5               NaN                 NaN         NaN                  auto   \n",
       "6               NaN                 NaN         NaN                  auto   \n",
       "8               NaN                 NaN         NaN                  auto   \n",
       "9               NaN                 NaN         NaN                  auto   \n",
       "10              NaN                 NaN         NaN                  auto   \n",
       "\n",
       "   nombre de candidats      score algo max  ...   id cible  \\\n",
       "5                    1  0.9742324561403508  ...  050121960   \n",
       "6                    1                 1.0  ...  02807808X   \n",
       "8                    1                 1.0  ...  027029549   \n",
       "9                    1                 1.0  ...  030260655   \n",
       "10                   1                 1.0  ...  033067414   \n",
       "\n",
       "                   forme principale cible type de cible 2 réservoir cible 2  \\\n",
       "5   Musorgskij, Modest Petrovič 1839-1881             NaN               NaN   \n",
       "6                Auric, Georges 1899-1983             NaN               NaN   \n",
       "8               Milhaud, Darius 1892-1974             NaN               NaN   \n",
       "9              Poulenc, Francis 1899-1963             NaN               NaN   \n",
       "10        Tailleferre, Germaine 1892-1983             NaN               NaN   \n",
       "\n",
       "   id cible 2 forme principale cible 2 type de cible 3 réservoir cible 3  \\\n",
       "5         NaN                      NaN             NaN               NaN   \n",
       "6         NaN                      NaN             NaN               NaN   \n",
       "8         NaN                      NaN             NaN               NaN   \n",
       "9         NaN                      NaN             NaN               NaN   \n",
       "10        NaN                      NaN             NaN               NaN   \n",
       "\n",
       "   id cible 3 forme principale cible 3  \n",
       "5         NaN                      NaN  \n",
       "6         NaN                      NaN  \n",
       "8         NaN                      NaN  \n",
       "9         NaN                      NaN  \n",
       "10        NaN                      NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import os\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "from pymarc import parse_xml_to_array\n",
    "import jellyfish\n",
    "from datetime import datetime\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # Remove copy in place warning for dataframe operations\n",
    "\n",
    "\n",
    "# Définition du fichier d'alignement à vérifier\n",
    "input_file_path = \"input/verif-auto-102024/rapport_20241030151058_alignement-défini_TEST Mat personnes_Tout.tsv\"\n",
    "\n",
    "# Définition du fichier de sortie pour les cas suspects\n",
    "output_file_root = \"output/verif-auto-102024/verif-auto-personnes-Mat\"\n",
    "\n",
    "# Faut-il exporter tous les alignements vérifiés avec une colonne identifiant les cas suspects (True),\n",
    "# ou exporter ces derniers à part (False)?\n",
    "output_in_place = True\n",
    "\n",
    "# Types d'alignement à vérifier\n",
    "valid_types = {'auto'}\n",
    "\n",
    "# Types de validation à effectuer\n",
    "validations = {'idref-local', 'dates', 'professions', 'similarité', 'auteur-titre'}\n",
    "# Les valeurs suivantes sont possibles:\n",
    "# - 'dates' -> compare les dates présentes dans les formes principales source et cible. PEUT être combiné avec 'idref-local'\n",
    "# - 'auteur-titre' ATTENTION cette validation fait un appel d'API IdRef. Utiliser uniquement lorsque nécessaire.\n",
    "# - 'idref-local' -> compare les sous-champs des notices source et cible. Nécessite l'accès à un export des notices IdRef et ATC/RNV\n",
    "# - 'professions' -> compare les sous-champs $c si présents. DOIT être combiné avec 'idref-local'\n",
    "# - 'similarité' -> tente de calculer un coéfficient de similarité entre les formes principales. PEUT être combiné avec 'idref-local'\n",
    "\n",
    "# Définition des fichiers exportés de IdRef et ATC/RNV pour comparaison des sous-champs. Utilisé uniquement en mode 'idref-local'\n",
    "idref_set = 'personnes'\n",
    "idref_records_folder = \"/Users/thomas/Documents/tmp-nobackup/bcu-rnv/idref-harvest-\" + idref_set\n",
    "atc_sets = ['personnes']\n",
    "atc_records_file_paths = [\"input/notices-detaillees/20241028_auth_mat_personnes_subf_a-d.tsv\"]\n",
    "\n",
    "# Pour limiter le chargement des fichiers IdRef (ex. pour tester), renseigner cette variable pour ne charger que les x premier fichiers.\n",
    "# Pour ne pas limiter, assigner la valeur -1\n",
    "idref_records_limit = -1\n",
    "\n",
    "# Fichiers temporaires pour accélérer le traitement successif lors de la comparaison des sous-champs. Si existants, ils sont utilisés\n",
    "# en mode 'idref-local' en lieu et place des notices complètes ci-dessus.\n",
    "idref_records_extract = \"input/idref-extrait-\" + idref_set + \"-comparaison.csv\"\n",
    "\n",
    "# Nom de la colonne ajoutée\n",
    "output_colname = \"validation auto\"\n",
    "\n",
    "# Lors des comparaisons textuelles, la distance calculée sera renseignée dans cette colonne\n",
    "distance_colname = \"distance validation\"\n",
    "\n",
    "# Définit la valeur de distance (rapportée à la longueur de la forme source) à partir de laquelle on considère qu'il y a une différence.\n",
    "distance_limit = 0.15\n",
    "\n",
    "# Ajoute une colonne avec des détails de comparaison, pour débogger\n",
    "debug_column = True\n",
    "\n",
    "# Définition des colonnes contenant les formes sources et cible à comparer\n",
    "source_form_colname = \"forme principale source\"\n",
    "target_form_colname = \"forme principale cible\"\n",
    "align_type_colname = \"décision d'alignement\"\n",
    "target_colname = \"réservoir cible\"\n",
    "target_candidatenr_colname = \"nombre de candidats\"\n",
    "idref_id_colname = \"id cible\"\n",
    "atc_id_colname = \"id source\"\n",
    "\n",
    "# Vérifier que tous les fichiers existent vraiment avant de continuer\n",
    "all_files = []\n",
    "for variable in [input_file_path, atc_records_file_paths]:\n",
    "    if isinstance(variable, list):\n",
    "        all_files.extend(variable)\n",
    "    else:\n",
    "        all_files.append(variable)\n",
    "\n",
    "for file in all_files:\n",
    "    if file and not os.path.isfile(file):\n",
    "        print(\"ATTENTION le fichier suivant n'existe pas: \",file)\n",
    "\n",
    "# Le fichier à vérifier est chargé dans une dataframe\n",
    "df = pd.read_csv(input_file_path, sep='\\t', dtype = str)\n",
    "print(df.shape)\n",
    "\n",
    "# Pour la comparaison, on retire les types d'alignements ignorés ainsi que les non-alignements\n",
    "df_filtered = df[(df[align_type_colname].isin(valid_types)) & (df[target_colname] == 'idref')]\n",
    "df_rest = df[(~df[align_type_colname].isin(valid_types)) | (df[target_colname] != 'idref')]\n",
    "print(df_filtered.shape)\n",
    "print(df_rest.shape)\n",
    "display(df_filtered.head())\n",
    "\n",
    "df_filtered.reset_index(drop=True, inplace=True)  # Drop indexes since we're not going to use them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e298d4-d73d-449f-b73f-38f78a6f4ed7",
   "metadata": {},
   "source": [
    "## Chargement des fichiers auxiliaires\n",
    "\n",
    "Si une comparaison utilisant les notices complètes IdRef et ATC/RNV est demandée, charger ces dernières dans un dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "415ef921-effc-479f-946c-27475c3dec8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4293697 notices IdRef chargées depuis input/idref-extrait-personnes-comparaison.csv\n",
      "951 notices ATC/RNV chargées depuis le fichier input/notices-detaillees/20241028_auth_mat_personnes_subf_a-d.tsv\n",
      "951 notices ATC/RNV chargées au total.\n",
      "--- Temps écoulé pour le chargement des fichiers: 0:00:10.449188 ---\n"
     ]
    }
   ],
   "source": [
    "# Fonctions nécessaires à traiter les fichiers XML provenant d'IdRef (Marc21)\n",
    "tps_debut_chargement = datetime.now()\n",
    "\n",
    "# Chargement des fichiers individuels\n",
    "def parse_marcxml_file(file_path):\n",
    "    records = []\n",
    "    with open(file_path, 'rb') as fh:\n",
    "        marc_records = parse_xml_to_array(fh)\n",
    "        for record in marc_records:\n",
    "            if record != None:\n",
    "                record_dict = extract_record_data(record)\n",
    "                if record_dict != None:\n",
    "                    records.append(record_dict)\n",
    "    return records\n",
    "\n",
    "# Extraction des champs nécessaires\n",
    "def extract_record_data(record):\n",
    "    field_001 = record.get('001')\n",
    "    if idref_set == 'personnes':\n",
    "        field_100 = record.get('100')\n",
    "        if field_001:\n",
    "            record_data = {\n",
    "                'idref_id' : field_001.data.replace('(IDREF)','').strip(),\n",
    "                '100a': field_100.get('a') if field_100 else None,\n",
    "                '100b': field_100.get('b') if field_100 else None,\n",
    "                '100c': field_100.get('c') if field_100 else None,\n",
    "                '100d': field_100.get('d') if field_100 else None\n",
    "            }\n",
    "        else:\n",
    "            return None\n",
    "    elif idref_set == 'collectivités':\n",
    "        field_110 = record.get('110')\n",
    "        field_111 = record.get('111')\n",
    "        field_411 = record.get('411')\n",
    "        if field_001:\n",
    "            record_data = {\n",
    "                'idref_id' : field_001.data.replace('(IDREF)','').strip(),\n",
    "                '110a': field_110.get('a') if field_110 else None,\n",
    "                '110b': field_110.get('b') if field_110 else None,\n",
    "                '110g': field_110.get('g') if field_110 else None,\n",
    "                '111a': field_111.get('a') if field_111 else None,\n",
    "                '111c': field_111.get('c') if field_111 else None,\n",
    "                '111d': field_111.get('d') if field_111 else None,\n",
    "                '111n': field_111.get('n') if field_111 else None,\n",
    "                '411a': field_111.get('a') if field_411 else None,\n",
    "                '411c': field_111.get('c') if field_411 else None,\n",
    "                '411d': field_111.get('d') if field_411 else None,\n",
    "                '411n': field_111.get('n') if field_411 else None\n",
    "            }\n",
    "    return record_data\n",
    "\n",
    "# Chargement des fichiers du dossier IdRef\n",
    "def load_marcxml_files_from_folder(folder_path, limit, status_display):\n",
    "    all_records = []\n",
    "    \n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.xml'): \n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            records = parse_marcxml_file(file_path)\n",
    "            all_records.extend(records)\n",
    "        status_display.value += 1\n",
    "        if (limit > 0 and status_display.value == limit):\n",
    "            break\n",
    "    \n",
    "    # Convert list of records to DataFrame\n",
    "    df = pd.DataFrame(all_records)\n",
    "    return df\n",
    "\n",
    "# Chargement des fichiers auxiliaires si on a choisi le type de validation 'idref-local'\n",
    "if 'idref-local' in validations:\n",
    "    \n",
    "    # Si un fichier CSV a été fourni (l'extraction a déjà été faite), charger les notices depuis ce fichier\n",
    "    if idref_records_extract and os.path.isfile(idref_records_extract):\n",
    "        idRef_df = pd.read_csv(idref_records_extract, dtype = str)\n",
    "        print(f\"{len(idRef_df.index)} notices IdRef chargées depuis {idref_records_extract}\")\n",
    "    else:\n",
    "        # Sinon, on prend une grande respiration et on charge tous les fichiers IdRef dans un dataframe\n",
    "        \n",
    "        # Affiche une barre de progression\n",
    "        if idref_records_limit > 0:\n",
    "            num_files = idref_records_limit\n",
    "        else:\n",
    "            num_files = sum(1 for entry in os.scandir(idref_records_folder) if entry.is_file() and entry.name.endswith('.xml'))\n",
    "        barre_attente_idRef = IntProgress(min=1, max=num_files, description=\"Chargement des fichiers IdRef: \", style={'description_width':'initial'},layout={'width':'80%'})\n",
    "        display(barre_attente_idRef)\n",
    "        \n",
    "        idRef_df = load_marcxml_files_from_folder(idref_records_folder, idref_records_limit, barre_attente_idRef)\n",
    "        \n",
    "        # Une fois le chargement terminé, on écrit le résultat dans un fichier CSV\n",
    "        if idref_records_extract:\n",
    "            idRef_df.to_csv(idref_records_extract, encoding=\"UTF-8\", index=False)\n",
    "    \n",
    "        print(f\"{len(idRef_df.index)} notices IdRef chargées depuis export OAI IdRef dans {idref_records_folder}\")\n",
    "    \n",
    "    # Utiliser l'identifiant IdRef comme index (pour accélérer les requêtes)\n",
    "    idRef_df.set_index('idref_id', inplace=True)\n",
    "    # Retirer les éventuels doublons\n",
    "    idRef_df = idRef_df[~idRef_df.index.duplicated(keep='first')]\n",
    "    \n",
    "    # Chargement des fichiers ATC/RNV\n",
    "    atc_df_list = []\n",
    "    for file_index, atc_records_file_path in enumerate(atc_records_file_paths):\n",
    "        if atc_records_file_path and os.path.isfile(atc_records_file_path):\n",
    "            atc_df_toadd = pd.read_csv(atc_records_file_path, sep='\\t', dtype = str)\n",
    "            atc_set = atc_sets[file_index]\n",
    "            # Extraire le contenu des sous-champs dans des colonnes distinctes (en enlevant les dernières virgules, si présentes)\n",
    "            if atc_set == 'personnes':\n",
    "                atc_df_toadd['100a'] = atc_df_toadd['subfields_content_for_tag2'].str.extract(r'\\$\\$a ([^$]+)')[0].str.replace(r'[,\\s]+$', '', regex=True)\n",
    "                atc_df_toadd['100b'] = atc_df_toadd['subfields_content_for_tag2'].str.extract(r'\\$\\$b ([^$]+)')[0].str.replace(r'[,\\s]+$', '', regex=True)\n",
    "                atc_df_toadd['100c'] = atc_df_toadd['subfields_content_for_tag2'].str.extract(r'\\$\\$c ([^$]+)')[0].str.replace(r'[,\\s]+$', '', regex=True)\n",
    "                atc_df_toadd['100d'] = atc_df_toadd['subfields_content_for_tag2'].str.extract(r'\\$\\$d ([^$]+)')[0].str.replace(r'[,\\s]+$', '', regex=True)\n",
    "            elif atc_set == 'collectivités':\n",
    "                atc_df_toadd['110a'] = atc_df_toadd['subfields_content_for_tag2'].str.extract(r'\\$\\$a ([^$]+)')[0].str.replace(r'[,\\s]+$', '', regex=True)\n",
    "                atc_df_toadd['110b'] = atc_df_toadd['subfields_content_for_tag2'].str.extract(r'\\$\\$b ([^$]+)')[0].str.replace(r'[,\\s]+$', '', regex=True)\n",
    "                atc_df_toadd['110g'] = atc_df_toadd['subfields_content_for_tag2'].str.extract(r'\\$\\$g ([^$]+)')[0].str.replace(r'[,\\s]+$', '', regex=True)\n",
    "            elif atc_set == 'congrès':\n",
    "                atc_df_toadd['111a'] = atc_df_toadd['subfields_content_for_tag2'].str.extract(r'\\$\\$a ([^$]+)')[0].str.replace(r'[,\\s]+$', '', regex=True)\n",
    "                atc_df_toadd['111c'] = atc_df_toadd['subfields_content_for_tag2'].str.extract(r'\\$\\$c ([^$]+)')[0].str.replace(r'[,\\s]+$|\\)', '', regex=True).str.strip()\n",
    "                atc_df_toadd['111d'] = atc_df_toadd['subfields_content_for_tag2'].str.extract(r'\\$\\$d ([^$]+)')[0].str.replace(r'[,\\s]+$|\\(|:', '', regex=True).str.strip()\n",
    "                atc_df_toadd['111n'] = atc_df_toadd['subfields_content_for_tag2'].str.extract(r'\\$\\$n ([^$]+)')[0].str.replace(r'[,\\s]+$|\\(|:', '', regex=True).str.strip()\n",
    "            atc_df_list.append(atc_df_toadd)\n",
    "            print(f\"{len(atc_df_toadd.index)} notices ATC/RNV chargées depuis le fichier {atc_records_file_path}\")\n",
    "        else:\n",
    "            print('Attention! Le fichier des notices ATC/RNV est manquant!')\n",
    "    atc_df = pd.concat(atc_df_list)\n",
    "    # Utiliser l'identifiant comme index (pour accélérer les requêtes)\n",
    "    atc_df.set_index('id', inplace=True)\n",
    "    print(f\"{len(atc_df.index)} notices ATC/RNV chargées au total.\")\n",
    "\n",
    "tps_fin_chargement = datetime.now()\n",
    "print(\"--- Temps écoulé pour le chargement des fichiers: %s ---\" % format(tps_fin_chargement - tps_debut_chargement))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818c4c80-3a91-416b-a0b2-127d0a24819d",
   "metadata": {},
   "source": [
    "## Définition des fonctions utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29825d8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fonction de comparaison des dates\n",
    "def date_compare(source_date,target_date):\n",
    "    source_date = str(source_date)\n",
    "    target_date = str(target_date)\n",
    "    # Ignorer les points d'interrogation\n",
    "    source_date = source_date.replace('?','')\n",
    "    target_date = target_date.replace('?','')\n",
    "    # Retirer le zéro en début de date\n",
    "    if source_date.startswith('0'):\n",
    "        source_date = source_date[1:0]\n",
    "    if target_date.startswith('0'):\n",
    "        target_date = target_date[1:0]\n",
    "    # Si l'une des dates à comparer est vide, on passe\n",
    "    if ((source_date == '') | (target_date == '')):\n",
    "        return False\n",
    "    # Si l'une des dates comporte des points, ne comparer que les chiffres entre eux\n",
    "    if (('.' in source_date) | ('.' in target_date)):\n",
    "        #print('Comparaison avec points: ' + source_date + ' et ' + target_date)\n",
    "        for char in range(0,len(source_date)):\n",
    "            if ((source_date[char] != '.') & (target_date[char] != '.') & (source_date[char] != target_date[char])):\n",
    "                #print('Je pense que ' + source_date[char] + ' != ' + target_date[char])\n",
    "                return True\n",
    "        return False\n",
    "    if (source_date != target_date):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Expression régulière pour trouver les dates\n",
    "date_pattern = r'(?:ca\\.|fl\\.)?([0-9\\.]{4}|\\?)-?([0-9\\.]{4}|\\?)?'\n",
    "\n",
    "# Vérification des auteurs-titre\n",
    "\n",
    "idref_base_url = 'https://idref.fr/'\n",
    "\n",
    "# Fonction utile pour déterminer si un champ MARC existe\n",
    "def contains_tag(data, tag_value):\n",
    "    return any(record['tag'] == tag_value for record in data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a7eb14-bbb9-4acc-8fce-747a795f6acb",
   "metadata": {},
   "source": [
    "## Moulinette de validation\n",
    "C'est là que tout se passe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6fefac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6ab7c9b7c74fc3a2694237b8c562be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=1, description=\"État d'avancement: \", layout=Layout(width='80%'), max=10416, min=1, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>réservoir source</th>\n",
       "      <th>id source</th>\n",
       "      <th>forme principale source</th>\n",
       "      <th>arbitre</th>\n",
       "      <th>date d'arbitrage</th>\n",
       "      <th>niveau de confiance</th>\n",
       "      <th>commentaire</th>\n",
       "      <th>décision d'alignement</th>\n",
       "      <th>nombre de candidats</th>\n",
       "      <th>score algo max</th>\n",
       "      <th>...</th>\n",
       "      <th>réservoir cible 2</th>\n",
       "      <th>id cible 2</th>\n",
       "      <th>forme principale cible 2</th>\n",
       "      <th>type de cible 3</th>\n",
       "      <th>réservoir cible 3</th>\n",
       "      <th>id cible 3</th>\n",
       "      <th>forme principale cible 3</th>\n",
       "      <th>validation auto</th>\n",
       "      <th>distance validation</th>\n",
       "      <th>debug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rnv</td>\n",
       "      <td>009950613</td>\n",
       "      <td>Moussorgski, Modeste</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9742324561403508</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vérifier forme principale</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>Dates [] et [('1839', '1881')] | Comparaison e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rnv</td>\n",
       "      <td>009950616</td>\n",
       "      <td>Auric, Georges</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK (levenshtein)</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>Dates [] et [('1899', '1983')] | Comparaison e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rnv</td>\n",
       "      <td>009950619</td>\n",
       "      <td>Milhaud, Darius</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK (levenshtein)</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>Dates [] et [('1892', '1974')] | Comparaison e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rnv</td>\n",
       "      <td>009950620</td>\n",
       "      <td>Poulenc, Francis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK (levenshtein)</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>Dates [] et [('1899', '1963')] | Comparaison e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rnv</td>\n",
       "      <td>009950621</td>\n",
       "      <td>Tailleferre, Germaine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK (levenshtein)</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>Dates [] et [('1892', '1983')] | Comparaison e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  réservoir source  id source  forme principale source arbitre  \\\n",
       "0              rnv  009950613   Moussorgski, Modeste       NaN   \n",
       "1              rnv  009950616         Auric, Georges       NaN   \n",
       "2              rnv  009950619        Milhaud, Darius       NaN   \n",
       "3              rnv  009950620       Poulenc, Francis       NaN   \n",
       "4              rnv  009950621  Tailleferre, Germaine       NaN   \n",
       "\n",
       "  date d'arbitrage niveau de confiance commentaire décision d'alignement  \\\n",
       "0              NaN                 NaN         NaN                  auto   \n",
       "1              NaN                 NaN         NaN                  auto   \n",
       "2              NaN                 NaN         NaN                  auto   \n",
       "3              NaN                 NaN         NaN                  auto   \n",
       "4              NaN                 NaN         NaN                  auto   \n",
       "\n",
       "  nombre de candidats      score algo max  ... réservoir cible 2 id cible 2  \\\n",
       "0                   1  0.9742324561403508  ...               NaN        NaN   \n",
       "1                   1                 1.0  ...               NaN        NaN   \n",
       "2                   1                 1.0  ...               NaN        NaN   \n",
       "3                   1                 1.0  ...               NaN        NaN   \n",
       "4                   1                 1.0  ...               NaN        NaN   \n",
       "\n",
       "  forme principale cible 2 type de cible 3 réservoir cible 3 id cible 3  \\\n",
       "0                      NaN             NaN               NaN        NaN   \n",
       "1                      NaN             NaN               NaN        NaN   \n",
       "2                      NaN             NaN               NaN        NaN   \n",
       "3                      NaN             NaN               NaN        NaN   \n",
       "4                      NaN             NaN               NaN        NaN   \n",
       "\n",
       "  forme principale cible 3            validation auto distance validation  \\\n",
       "0                      NaN  Vérifier forme principale            0.631579   \n",
       "1                      NaN           OK (levenshtein)            0.076923   \n",
       "2                      NaN           OK (levenshtein)            0.071429   \n",
       "3                      NaN           OK (levenshtein)            0.066667   \n",
       "4                      NaN           OK (levenshtein)            0.050000   \n",
       "\n",
       "                                               debug  \n",
       "0  Dates [] et [('1839', '1881')] | Comparaison e...  \n",
       "1  Dates [] et [('1899', '1983')] | Comparaison e...  \n",
       "2  Dates [] et [('1892', '1974')] | Comparaison e...  \n",
       "3  Dates [] et [('1899', '1963')] | Comparaison e...  \n",
       "4  Dates [] et [('1892', '1983')] | Comparaison e...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'appels d'API: 779 (7% des alignements)\n",
      "--- Temps écoulé pour la comparaison des alignements: 0:28:31.757764 ---\n"
     ]
    }
   ],
   "source": [
    "# Affiche une barre de progression\n",
    "numrows = df_filtered.shape[0]\n",
    "barre_attente = IntProgress(min=1, max=numrows, description=\"État d'avancement: \", style={'description_width':'initial'},layout={'width':'80%'})\n",
    "display(barre_attente)\n",
    "\n",
    "if not(output_in_place):\n",
    "    wrong_dates = []\n",
    "    wrong_types = []\n",
    "    wrong_forms = []\n",
    "    misc_errors = []\n",
    "\n",
    "nb_api_calls = 0\n",
    "\n",
    "tps_debut_moulinette = datetime.now()\n",
    "\n",
    "for index, row in df_filtered.iterrows():\n",
    "    if not ((row[source_form_colname] == '') | (row[target_form_colname] == '') | pd.isnull(row[source_form_colname]) | pd.isnull(row[target_form_colname])):\n",
    "\n",
    "        source_dates = ''\n",
    "        target_dates = ''\n",
    "        verif_dates = False\n",
    "\n",
    "        source_term = ''\n",
    "        target_term = ''\n",
    "\n",
    "        notice_idref = None\n",
    "        notice_atc = None\n",
    "\n",
    "        distance = None\n",
    "\n",
    "        debug_output = ''\n",
    "        \n",
    "        # Procéder à la validation en utilisant les notices complètes IdRef et ATC/RNV si demandé\n",
    "        \n",
    "        if 'idref-local' in validations:\n",
    "            # La validation ne peut se faire que si les notices complètes existent\n",
    "            try:\n",
    "                notice_idref = idRef_df.loc[row[idref_id_colname]]\n",
    "            except (KeyError, TypeError) as e:\n",
    "                # Ignorer cette ligne s'il manque une des données requises\n",
    "                pass\n",
    "            try:\n",
    "                notice_atc = atc_df.loc[row[atc_id_colname]]\n",
    "            except (KeyError, TypeError) as e:\n",
    "                # Ignorer cette ligne s'il manque une des données requises\n",
    "                pass\n",
    "            if 'dates' in validations:\n",
    "                try:\n",
    "                    source_dates = re.findall(date_pattern, notice_atc['100d'])\n",
    "                except (KeyError, TypeError) as e:\n",
    "                    # Ignorer cette ligne s'il manque une des données requises\n",
    "                    pass\n",
    "                try:\n",
    "                    target_dates = re.findall(date_pattern, notice_idref['100d'])\n",
    "                except (KeyError, TypeError) as e:\n",
    "                    # Ignorer cette ligne s'il manque une des données requises\n",
    "                    pass\n",
    "            if 'similarité' in validations:\n",
    "                try:\n",
    "                    source_term = notice_atc['100a']\n",
    "                except (KeyError, TypeError) as e:\n",
    "                    # Ignorer cette ligne s'il manque une des données requises\n",
    "                    pass\n",
    "                try:\n",
    "                    target_term = notice_idref['100a']\n",
    "                except (KeyError, TypeError) as e:\n",
    "                    # Ignorer cette ligne s'il manque une des données requises\n",
    "                    pass\n",
    "            if 'professions' in validations:\n",
    "                try:\n",
    "                    source_prof = notice_atc['100c']\n",
    "                    target_prof = notice_idref['100c']\n",
    "                    distance_prof = jellyfish.levenshtein_distance(source_prof,target_prof)/len(source_prof)\n",
    "                    if distance_prof > distance_limit:\n",
    "                        if (output_in_place):\n",
    "                            df_filtered.loc[index, output_colname] = \"Vérifier professions\"\n",
    "                            df_filtered.loc[index, distance_colname] = distance_prof\n",
    "                    elif (output_in_place):\n",
    "                            df_filtered.loc[index, output_colname] = \"OK ($$c)\"\n",
    "                except (KeyError, TypeError) as e:\n",
    "                    # Ignorer cette validation s'il manque une des données requises\n",
    "                    pass\n",
    "        \n",
    "        # Extraire les dates de la forme principale si on ne les a pas trouvées dans les sous-champs'\n",
    "        if len(source_dates) < 1:\n",
    "            source_dates = re.findall(date_pattern, row[source_form_colname])\n",
    "        if len(target_dates) < 1:\n",
    "            target_dates = re.findall(date_pattern, row[target_form_colname])\n",
    "\n",
    "        if debug_column:\n",
    "            debug_output = debug_output + f\"Dates {source_dates} et {target_dates} | \"\n",
    "        \n",
    "        # Validation de date si elles sont présentes des deux côtés et si demandé\n",
    "        if ((len(source_dates) > 0) and (len(target_dates) > 0) and ('dates' in validations)):\n",
    "            if (date_compare(source_dates[0][0],target_dates[0][0]) | date_compare(source_dates[0][1],target_dates[0][1])):\n",
    "                # Cas potentiel de dates qui ne correspondent pas\n",
    "                if (output_in_place):\n",
    "                    df_filtered.loc[index, output_colname] = \"Vérifier dates\"\n",
    "                else:\n",
    "                    wrong_dates.append(row)\n",
    "            else:\n",
    "                # Les dates semblent correspondre, utiliser cette information pour valider l'alignement\n",
    "                verif_dates = True\n",
    "                df_filtered.loc[index, output_colname] = \"OK (dates)\"\n",
    "\n",
    "        \n",
    "        # Utiliser les formes simples pour la similarité textuelle (sans chiffres et signes de ponctuation) si on n'a pas pu extraire le sous-champ $a\n",
    "        if len(source_term) < 1:\n",
    "            source_term = re.sub(r'[\\d,-.\\?()]', '', row[source_form_colname]).strip()\n",
    "\n",
    "        if len(target_term) < 1:\n",
    "            target_term = re.sub(r'[\\d,-.\\?()]', '', row[target_form_colname]).strip()\n",
    "\n",
    "        if debug_column:\n",
    "            debug_output = debug_output + f\"Comparaison entre {source_term} et {target_term} | \"\n",
    "        \n",
    "        # Calculer la similarité textuelle si demandé\n",
    "        if (len(source_term) > 0) and (len(target_term) > 0) and ('similarité' in validations):\n",
    "            distance = jellyfish.levenshtein_distance(source_term,target_term)/len(source_term)\n",
    "            if debug_column:\n",
    "                debug_output = debug_output + f\"distance: {str(distance)} | \"\n",
    "\n",
    "        if (distance is not None and distance > distance_limit and not(verif_dates)):\n",
    "            # Signaler comme erreur potentielle sauf si validé par les dates\n",
    "            if (output_in_place):\n",
    "                df_filtered.loc[index, output_colname] = \"Vérifier forme principale\"\n",
    "                df_filtered.loc[index, distance_colname] = distance\n",
    "            else:\n",
    "                wrong_forms.append(row)\n",
    "        elif (distance is not None and distance <= distance_limit and not(verif_dates) and output_in_place):\n",
    "                df_filtered.loc[index, output_colname] = \"OK (levenshtein)\"\n",
    "                df_filtered.loc[index, distance_colname] = distance\n",
    "\n",
    "        \n",
    "        # Vérifier si la notice IdRef vers laquelle on aligne est de type auteur-titre, seulement si demandé\n",
    "        if 'auteur-titre' in validations:\n",
    "            if notice_idref is None:\n",
    "                # Si la notice cible n'est pas disponible localement, il ne s'agit probablement pas d'une notice de type auteur\n",
    "                # Faire un appel d'API pour en avoir le coeur net.\n",
    "                # ATTENTION cette étape est très coûteuse en temps\n",
    "                idref_id = row[idref_id_colname]\n",
    "                url = idref_base_url + str(idref_id) + '.json'\n",
    "                #print(\"Appel d'API pour \" + str(idref_id))\n",
    "                nb_api_calls += 1\n",
    "                # Appel d'API\n",
    "                idref_result = requests.get(url)\n",
    "                if (idref_result.status_code == 200):\n",
    "                    # Identifier si le résultat contient un champ 240\n",
    "                    if contains_tag(idref_result.json()['record']['datafield'], 240):\n",
    "                        if (output_in_place):\n",
    "                            df_filtered.loc[index, output_colname] = \"Cible de type auteur-titre\"\n",
    "                        else:\n",
    "                            wrong_types.append(row)\n",
    "                else:\n",
    "                    # Erreur de requête API\n",
    "                    if (output_in_place):\n",
    "                        df_filtered.loc[index, output_colname] = \"Erreur de requête API IdRef. Code:\" + str(idref_result.status_code)\n",
    "                    else:\n",
    "                        misc_errors.append(row)\n",
    "    \n",
    "    else:\n",
    "        # Il manque un des champs à comparer, autre erreur\n",
    "        if (output_in_place):\n",
    "            df_filtered.loc[index, output_colname] = \"Erreur de validation\"\n",
    "        else:\n",
    "            misc_errors.append(row)\n",
    "    \n",
    "    if debug_column:\n",
    "        df_filtered.loc[index, \"debug\"] = debug_output\n",
    "    \n",
    "    barre_attente.value += 1\n",
    "\n",
    "display(df_filtered.head())\n",
    "\n",
    "tps_fin_moulinette = datetime.now()\n",
    "print(\"Nombre d'appels d'API: \" + str(nb_api_calls) + \" (\" + str(round(nb_api_calls/numrows*100)) + \"% des alignements)\")\n",
    "print(\"--- Temps écoulé pour la comparaison des alignements: %s ---\" % format(tps_fin_moulinette - tps_debut_moulinette))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff07abd-af61-4e38-b7e7-a1dc7b70dd5e",
   "metadata": {},
   "source": [
    "## Exports des fichiers de résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1745443-8bcd-4477-a546-dfc4f47a1373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10416, 26)\n",
      "(19195, 26)\n",
      "--- Temps écoulé pour sauvegarder les fichiers: 0:00:09.097654 ---\n",
      "--- Temps total écoulé: 0:28:51.345674 ---\n"
     ]
    }
   ],
   "source": [
    "tps_debut_sauvegarde = datetime.now()\n",
    "\n",
    "if not(output_in_place):\n",
    "    wrong_dates_df = pd.DataFrame(wrong_dates)\n",
    "    wrong_forms_df = pd.DataFrame(wrong_forms)\n",
    "    misc_errors_df = pd.DataFrame(misc_errors)\n",
    "\n",
    "    wrong_dates_df.to_excel(output_file_root + \"_dates.xlsx\",index=False)\n",
    "    wrong_forms_df.to_excel(output_file_root + \"_formes.xlsx\",index=False)\n",
    "    misc_errors_df.to_excel(output_file_root + \"_erreurs.xlsx\",index=False)\n",
    "else:\n",
    "    print(df_filtered.shape)\n",
    "    # Combiner le fichier filtré qui a été validé avec les alignements retirés au début\n",
    "    df_output = pd.concat([df_filtered,df_rest])\n",
    "    print(df_output.shape)\n",
    "    df_output.to_excel(output_file_root + \"_tout.xlsx\",index=False)\n",
    "\n",
    "tps_fin_sauvegarde = datetime.now()\n",
    "print(\"--- Temps écoulé pour sauvegarder les fichiers: %s ---\" % format(tps_fin_sauvegarde - tps_debut_sauvegarde))\n",
    "print(\"--- Temps total écoulé: %s ---\" % format(tps_fin_sauvegarde - tps_debut_chargement))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
